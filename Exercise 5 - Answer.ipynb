{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dn-6c02VmqiN"
   },
   "outputs": [],
   "source": [
    "import os       #文件操作的库\n",
    "import zipfile   #文件解压的库\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop    #网络训练，优化算法\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator    #图的预处理\n",
    "from shutil import copyfile  #对文件进行复制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3sd9dQWa23aj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' 不是内部或外部命令，也不是可运行的程序\n",
      "或批处理文件。\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'zipfile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-be6564820216>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mlocal_zip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'/tmp/cats-and-dogs.zip'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mzip_ref\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_zip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/tmp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'zipfile' is not defined"
     ]
    }
   ],
   "source": [
    "# If the URL doesn't work, visit https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765\n",
    "# And right click on the 'Download Manually' link to get a new URL to the dataset\n",
    "\n",
    "# Note: This is a very large dataset and will take time to download\n",
    "\n",
    "!wget --no-check-certificate \\      #wget进行数据下载\n",
    "    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\" \\\n",
    "    -O \"/tmp/cats-and-dogs.zip\"     #存在云服务器了，记得改路径\n",
    "\n",
    "local_zip = '/tmp/cats-and-dogs.zip'\n",
    "zip_ref   = zipfile.ZipFile(local_zip, 'r')    #只读\n",
    "zip_ref.extractall('/tmp')    #解压到此\n",
    "zip_ref.close()    #解压后关闭\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DM851ZmN28J3"
   },
   "outputs": [],
   "source": [
    "print(len(os.listdir('/tmp/PetImages/Cat/')))   #有len看下有多少数据\n",
    "print(len(os.listdir('/tmp/PetImages/Dog/')))\n",
    "\n",
    "# Expected Output:\n",
    "# 12501\n",
    "# 12501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-QkLjxpmyK2"
   },
   "outputs": [],
   "source": [
    "try:                          #对训练和测试的狗毛猫数据分别放到一个独立的文件夹里面\n",
    "    os.mkdir('/tmp/cats-v-dogs')\n",
    "    os.mkdir('/tmp/cats-v-dogs/training')\n",
    "    os.mkdir('/tmp/cats-v-dogs/testing')\n",
    "    os.mkdir('/tmp/cats-v-dogs/training/cats')\n",
    "    os.mkdir('/tmp/cats-v-dogs/training/dogs')\n",
    "    os.mkdir('/tmp/cats-v-dogs/testing/cats')\n",
    "    os.mkdir('/tmp/cats-v-dogs/testing/dogs')\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zvSODo0f9LaU"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "#把解压后的数据分为测试机和训练集，SPLIT_SIZE是划分比例\n",
    "#SOURCE 就是解压后存储训练和测试数据文件的文件夹\n",
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "    files = []\n",
    "    for filename in os.listdir(SOURCE):   \n",
    "        file = SOURCE + filename     #这个有意思，文件名拼接打开对应文件\n",
    "        if os.path.getsize(file) > 0:   #是非空图片的话存一下\n",
    "            files.append(filename)\n",
    "        else:\n",
    "            print(filename + \" is zero length, so ignoring.\")\n",
    "\n",
    "    training_length = int(len(files) * SOURCE)    #SOURCE 是0.9的话就说明训练数据占有90%\n",
    "    testing_length = int(len(files) - training_length)\n",
    "    shuffled_set = random.sample(files, len(files))   #把图片顺序打乱\n",
    "    training_set = shuffled_set[0:training_length]   #切片抽取训练样本集\n",
    "    testing_set = shuffled_set[-testing_length:]\n",
    "\n",
    "    for filename in training_set:    #读取训练样本集\n",
    "        this_file = SOURCE + filename    #SOURCE 是存放狗猫数据原路径，加上训练集的名字\n",
    "        destination = TRAINING + filename\n",
    "        copyfile(this_file, destination)\n",
    "\n",
    "    for filename in testing_set:  #读取测试样本集\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TESTING + filename\n",
    "        copyfile(this_file, destination)   #用这个命令读进来，读到训练样本集中，读进去，放到destination\n",
    "\n",
    "\n",
    "CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"            #猫的数据\n",
    "TRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"   #训练样本的目录\n",
    "TESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"     #测试样本的目录\n",
    "DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"            #狗的数据\n",
    "TRAINING_DOGS_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\n",
    "TESTING_DOGS_DIR = \"/tmp/cats-v-dogs/testing/dogs/\"\n",
    "\n",
    "def create_dir(file_dir):      #产生路径（文件夹）的命令\n",
    "    if os.path.exists(file_dir):    #如果路径存在\n",
    "        print('true')\n",
    "        #os.rmdir(file_dir)\n",
    "        shutil.rmtree(file_dir)#删除\n",
    "        os.makedirs(file_dir)  #再建立\n",
    "    else:\n",
    "        os.makedirs(file_dir)\n",
    "\n",
    "#前面已经生成，再做确认而已\n",
    "#生成四个子目录，存在的话会显示 True，删除再建立一个空的，没有的话就再建立\n",
    "create_dir(TRAINING_CATS_DIR)\n",
    "create_dir(TESTING_CATS_DIR)\n",
    "create_dir(TRAINING_DOGS_DIR)\n",
    "create_dir(TESTING_CATS_DIR)\n",
    "    \n",
    "#做调用切分的，切分比例为 9:1\n",
    "split_size = .9\n",
    "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
    "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)\n",
    "\n",
    "# Expected output\n",
    "# 666.jpg is zero length, so ignoring\n",
    "# 11702.jpg is zero length, so ignoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hwHXFhVG3786"
   },
   "outputs": [],
   "source": [
    "#os.listdir 列出本路径下有多少文件（图片）\n",
    "print(len(os.listdir('/tmp/cats-v-dogs/training/cats/')))\n",
    "print(len(os.listdir('/tmp/cats-v-dogs/training/dogs/')))\n",
    "print(len(os.listdir('/tmp/cats-v-dogs/testing/cats/')))\n",
    "print(len(os.listdir('/tmp/cats-v-dogs/testing/dogs/')))\n",
    "\n",
    "# Expected output:\n",
    "# 11250\n",
    "# 11250\n",
    "# 1250\n",
    "# 1250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-BQrav4anTmj"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ed8fe615894e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model = tf.keras.models.Sequential([\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "#搭建神经网络\n",
    "model = tf.keras.models.Sequential([\n",
    "    #Sequential 表示每一行为一层，每层之间是顺序连接的\n",
    "    #16 32 64 512 1 都表示通道，随着隐层的加深，通道的数量也是逐步增加的\n",
    "    #3*3 是卷积核的大小\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),  #卷积\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),                                                #最大池化\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),         #把最后的最大池化层拉直了？\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),   #接一个全连接的影层\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')   #输出层\n",
    "    #因为是猫狗二分类，所以输出层神经元可以使一个也可以是两个\n",
    "    #如果输出接近 1，认为是狗；接近 0， 认为是猫\n",
    "    #输出层用的 sigmoid 激活函数，其他用 relu 做激活函数\n",
    "])\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['acc'])\n",
    "#训练步长初始为 0.001，用 RMSprop 来修订步长；这个网络的损失函数，用了一个二元的交叉熵；网络性能的度量，用的是准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fQrZfVgz4j2g"
   },
   "outputs": [],
   "source": [
    "#这里是要做图像预处理\n",
    "TRAINING_DIR = \"/tmp/cats-v-dogs/training/\"\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.)  #Imag...把训练的样本集做规划为 0~1 之间，减少计算量\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                    batch_size=100,   #100 个样本作为一批，共 n/100 批\n",
    "                                                                      #一个 epochs 就是总共的训练样本除以100\n",
    "                                                                      #batch_size 就是我们一个 epochs 要循环的轮次\n",
    "                                                    class_mode='binary',   #类别为 binary 这是二分类\n",
    "                                                    target_size=(150, 150))  #把图片做成 150*150 的\n",
    "\n",
    "VALIDATION_DIR = \"/tmp/cats-v-dogs/testing/\"\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
    "                                                              batch_size=100,  \n",
    "                                                              class_mode='binary',\n",
    "                                                              target_size=(150, 150))\n",
    "\n",
    "# Expected Output:\n",
    "# Found 22498 images belonging to 2 classes.\n",
    "# Found 2500 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5qE1G6JB4fMn"
   },
   "outputs": [],
   "source": [
    "# Note that this may take some time.\n",
    "history = model.fit_generator(train_generator,\n",
    "                              epochs=2,     #epochs=2 指要训练两轮，可以自己改数值\n",
    "                              verbose=1,    #是否要记录，1 表示要\n",
    "                              validation_data=validation_generator)\n",
    "#一轮表示所有样本都要参加梯度下降，每批只能对 100 个样本进行训练，所以要进行 225 批训练（题目而定）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWZrJN4-65RC"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.image  as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc=history.history['acc']      #计算训练样本准确度\n",
    "val_acc=history.history['val_acc']  #计算测试样本准确度\n",
    "loss=history.history['loss']     #计算训练样本损失函数\n",
    "val_loss=history.history['val_loss']  #计算测试样本损失函数\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.figure()\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "# Desired output. Charts with training and validation metrics. No crash :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LqL6FYUrtXpf"
   },
   "outputs": [],
   "source": [
    "# Here's a codeblock just for fun. You should be able to upload an image here \n",
    "# and have it classified without crashing\n",
    "import numpy as np\n",
    "from google.colab import files\n",
    "from keras.preprocessing import image\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    " \n",
    "  # predicting images\n",
    "  path = '/content/' + fn\n",
    "  img = image.load_img(path, target_size=(150, 150))   #加载新的图片\n",
    "  x = image.img_to_array(img)   #由列表变成向量的形式，X 是一个多维的数组\n",
    "  x = np.expand_dims(x, axis=0)   #拉直成相应的向量\n",
    "\n",
    "  images = np.vstack([x])    用 vatack 按照水平方向把各个通道的数据连接起来构成一个长向量\n",
    "  classes = model.predict(images, batch_size=10)\n",
    "  print(classes[0])\n",
    "  if classes[0]>0.5: \n",
    "    print(fn + \" is a dog\")\n",
    "  else:\n",
    "    print(fn + \" is a cat\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Exercise 5 - Answer.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
